# üöÄ Plano de Execu√ß√£o V3 - MVP em 2 Semanas

**Data de In√≠cio**: 2025-12-01
**Data de Conclus√£o**: 2025-12-14
**Status**: üî• PRONTO PARA COME√áAR

---

## üéØ Objetivo do MVP

Transformar Agente Daktus QA de **auditoria passiva** (v2) para **corre√ß√£o ativa** (v3):
- Aplicar melhorias automaticamente no JSON do protocolo
- Suportar protocolos JSON massivos (3k-5k+ linhas)
- Reduzir tempo de implementa√ß√£o: dias ‚Üí minutos (-90%)
- Reduzir custo de tokens em 50% via cache agressivo

---

## üìÖ Cronograma Detalhado

### **DIA 1 (2025-12-01) - VALIDA√á√ÉO CR√çTICA** ‚ö°

**Objetivo**: Provar que auto-apply funciona antes de implementar

#### Tarefas
1. **Setup do Ambiente V3**
   - [ ] Criar branch `v3-mvp` no repo atual
   - [ ] Copiar estrutura v2 como base
   - [ ] Criar pasta `src/agent_v3/` vazia
   - [ ] Atualizar .gitignore se necess√°rio

2. **Experimento Auto-Apply (CR√çTICO)**
   - [ ] Pegar 5 protocolos reais (variados em tamanho/especialidade)
   - [ ] Rodar v2 ‚Üí gerar relat√≥rios com sugest√µes
   - [ ] Criar script experimental: `validate_auto_apply.py`
   - [ ] Prompt para Sonnet 4.5: "Aplique estas sugest√µes no JSON"
   - [ ] Revisar manualmente cada resultado:
     - JSON v√°lido? (testar com `json.loads()`)
     - L√≥gica cl√≠nica preservada?
     - Mudan√ßas corretas aplicadas?
     - Rastreabilidade mantida?

3. **M√©tricas de Valida√ß√£o**
   - [ ] % de sucesso (meta: >80%)
   - [ ] Tipos de erro encontrados
   - [ ] Tempo economizado vs implementa√ß√£o manual
   - [ ] Custo de tokens por protocolo

**Decis√£o GO/NO-GO**:
- ‚úÖ **Se >80% sucesso** ‚Üí Implementar Fase 5 (ImprovementApplicator) nos dias 5-7
- ‚ö†Ô∏è **Se 60-80% sucesso** ‚Üí Refinar prompt, iterar 1-2 vezes
- ‚ùå **Se <60% sucesso** ‚Üí Reavaliar abordagem (talvez assistido, n√£o autom√°tico)

**Entreg√°vel**: Relat√≥rio de valida√ß√£o em `reports/auto_apply_validation.md`

---

### **DIAS 2-4 (2025-12-02 a 04) - Compacta√ß√£o de Protocolos JSON** üóúÔ∏è

**Objetivo**: Resolver gargalo de protocolos grandes (>3k linhas)

#### DIA 2 - An√°lise e Design
- [ ] Analisar 10+ protocolos reais (medir linhas, tokens, estrutura)
- [ ] Identificar redund√¢ncias: metadados desnecess√°rios, campos duplicados
- [ ] Definir schema "essencial cl√≠nico" (o que DEVE manter)
- [ ] Projetar arquitetura JSONCompactor
- [ ] Documentar em `src/agent_v3/json_compactor/README.md`

#### DIA 3 - Implementa√ß√£o JSONCompactor
- [ ] Criar `src/agent_v3/json_compactor/compactor.py`
- [ ] Fun√ß√£o: `compact_protocol(protocol_json) -> compacted_json`
- [ ] Remo√ß√£o de metadados desnecess√°rios
- [ ] Preservar: estrutura cl√≠nica, fluxos, vari√°veis, l√≥gica de decis√£o
- [ ] Criar fun√ß√£o reversa: `reconstruct_protocol(compacted, original) -> full_json`
- [ ] Unit tests: testar com 5 protocolos diferentes

#### DIA 4 - SmartChunking (se necess√°rio)
- [ ] Avaliar: compacta√ß√£o resolve o problema?
- [ ] Se n√£o resolver: implementar SmartChunking
  - [ ] Dividir JSON por se√ß√µes l√≥gicas (s√≠ndromes, fluxos)
  - [ ] Criar `src/agent_v3/chunking/smart_chunker.py`
  - [ ] Fun√ß√£o: `chunk_protocol(protocol_json) -> chunks[]`
  - [ ] Fun√ß√£o: `merge_chunks(chunks[], improvements[]) -> full_protocol`
- [ ] Testar com os 3 maiores protocolos (>3k linhas)

**Entreg√°vel**: JSONCompactor funcional, testado com 10+ protocolos

---

### **DIAS 5-7 (2025-12-05 a 07) - Auto-Apply Engine** üî•

**Objetivo**: Implementar core engine de aplica√ß√£o autom√°tica de melhorias

#### DIA 5 - ImprovementApplicator
- [ ] Criar `src/agent_v3/applicator/improvement_applicator.py`
- [ ] Fun√ß√£o principal:
  ```python
  apply_improvements(
      protocol_json: dict,
      suggestions: list,
      model: str = "anthropic/claude-sonnet-4.5"
  ) -> dict:
      # Retorna: {
      #   "fixed_protocol": {...},
      #   "changes": [...],
      #   "confidence_scores": {...}
      # }
  ```
- [ ] Prompt engineering: instru√ß√£o clara para Sonnet 4.5
  - Input: protocolo + sugest√µes
  - Output: protocolo corrigido + diff + justificativa por mudan√ßa
- [ ] Implementar chamada ao LLM com cache
- [ ] Testar com 3-5 protocolos reais

#### DIA 6 - StructuralValidator + ConfidenceScoring
- [ ] Criar `src/agent_v3/validator/structural_validator.py`
- [ ] Valida√ß√µes obrigat√≥rias:
  - [ ] JSON v√°lido (sintaxe)
  - [ ] Schema preservado (estrutura n√£o quebrou)
  - [ ] Todas as chaves obrigat√≥rias presentes
  - [ ] Tipos de dados corretos
- [ ] Criar `src/agent_v3/scoring/confidence_scorer.py`
- [ ] Implementar scoring b√°sico:
  - Complexidade da mudan√ßa
  - √Årea do protocolo afetada (cr√≠tica vs n√£o-cr√≠tica)
  - Clareza da sugest√£o original
  - Threshold: >90% = auto-apply, 70-90% = preview, <70% = manual
- [ ] Integrar valida√ß√£o + scoring no pipeline

#### DIA 7 - DiffGenerator + Testes
- [ ] Criar `src/agent_v3/diff/diff_generator.py`
- [ ] Formato de diff leg√≠vel:
  ```
  MUDAN√áA 1: Adicionado exame "Hemograma completo"
  Localiza√ß√£o: node_id="sintomas_anemicos" ‚Üí conditions
  Antes: [...]
  Depois: [..., "hemograma_completo"]
  Justificativa: Playbook recomenda hemograma para sintomas de anemia
  Confian√ßa: 95%
  ```
- [ ] Testes end-to-end:
  - [ ] Rodar v2 ‚Üí sugest√µes
  - [ ] Rodar v3 ‚Üí protocolo corrigido
  - [ ] Validar estrutura + diff + rastreabilidade
  - [ ] Comparar com implementa√ß√£o manual (tempo/qualidade)

**Entreg√°vel**: Auto-Apply Engine funcional e testado

---

### **DIA 8 (2025-12-08) - Prompt Caching Agressivo** üí∞

**Objetivo**: Reduzir custo de tokens em 50-70%

#### Tarefas
- [ ] Revisar `src/agent_v2/llm_client.py` (j√° tem cache ephemeral)
- [ ] Implementar estrat√©gia 100% cache em `src/agent_v3/llm_client.py`:
  - [ ] Playbook sempre em cache (system message com cache_control)
  - [ ] Protocolo original em cache (n√£o muda entre itera√ß√µes)
  - [ ] Instru√ß√µes de sistema em cache
  - [ ] Apenas output vari√°vel sem cache
- [ ] Criar `src/agent_v3/monitoring/cache_monitor.py`
  - [ ] Logar cache hit/miss rate
  - [ ] Calcular economia de tokens
  - [ ] Alertar se cache n√£o funciona
- [ ] Testar com 10 an√°lises consecutivas (medir economia real)

**Entreg√°vel**: Cache 100%, economia >50% validada

---

### **DIA 9 (2025-12-09) - Impact Scoring via Prompt** üéØ

**Objetivo**: Priorizar sugest√µes por impacto (quick win)

#### Tarefas
- [ ] Ajustar `src/config/prompts/super_prompt.py` para incluir scores:
  ```json
  {
    "priority": "critical",
    "category": "missing_red_flag",
    "description": "...",
    "impact_scores": {
      "patient_safety": 9,  // 0-10
      "financial_impact": "high",  // low/medium/high
      "implementation_effort": "low"  // low/medium/high
    }
  }
  ```
- [ ] Atualizar `src/agent_v2/output/validator.py` para validar novos campos
- [ ] Atualizar `src/cli/run_qa_cli.py` para rankear sugest√µes por impacto
- [ ] Testar com 5 protocolos reais (verificar se scores fazem sentido)

**Entreg√°vel**: Sugest√µes ranqueadas por impacto no relat√≥rio

---

### **DIA 10 (2025-12-10) - Integra√ß√£o V2 + V3** üîó

**Objetivo**: Pipeline unificado v2 (an√°lise) + v3 (corre√ß√£o)

#### Tarefas
- [ ] Criar `src/agent_v3/pipeline.py` como orquestrador:
  ```python
  analyze_and_fix(
      protocol_path,
      playbook_path,
      model="anthropic/claude-sonnet-4.5",
      auto_apply=True,
      confidence_threshold=0.90
  ) -> dict
  ```
- [ ] Fluxo integrado:
  1. Rodar v2 ‚Üí an√°lise + sugest√µes
  2. JSONCompactor ‚Üí reduzir protocolo se necess√°rio
  3. ImprovementApplicator ‚Üí aplicar melhorias
  4. StructuralValidator ‚Üí validar resultado
  5. ConfidenceScoring ‚Üí avaliar confian√ßa
  6. DiffGenerator ‚Üí gerar diff
  7. Retornar tudo unificado
- [ ] Criar CLI para v3: `run_qa_v3_cli.py`
- [ ] Testar pipeline completo com 3-5 protocolos

**Entreg√°vel**: Pipeline v3 funcional end-to-end

---

### **DIAS 11-13 (2025-12-11 a 13) - Testes Intensivos** üß™

**Objetivo**: Validar v3 com casos reais de m√∫ltiplas especialidades

#### DIA 11 - Testes de Funcionalidade
- [ ] Testar com 20+ protocolos reais:
  - ORL
  - AVC
  - Reumatologia
  - Doen√ßas Infecciosas
  - Outros
- [ ] Medir para cada protocolo:
  - [ ] Taxa de sucesso (auto-apply sem erros)
  - [ ] Tempo de execu√ß√£o
  - [ ] Custo de tokens
  - [ ] Cache hit rate
  - [ ] Qualidade das corre√ß√µes (review manual)

#### DIA 12 - Testes de Edge Cases
- [ ] Protocolos muito pequenos (<100 linhas)
- [ ] Protocolos muito grandes (>5k linhas)
- [ ] Protocolos com estrutura n√£o-padr√£o
- [ ] Playbooks muito grandes (>50 p√°ginas)
- [ ] Playbooks muito pequenos (<5 p√°ginas)
- [ ] Casos sem playbook (usar apenas protocolo)

#### DIA 13 - Corre√ß√µes e Refinamento
- [ ] Corrigir bugs encontrados
- [ ] Refinar prompts que geraram outputs ruins
- [ ] Otimizar performance (se necess√°rio)
- [ ] Documentar limita√ß√µes conhecidas
- [ ] Preparar casos de sucesso para apresenta√ß√£o

**Entreg√°vel**: V3 testado e validado em produ√ß√£o

---

### **DIA 14 (2025-12-14) - Apresenta√ß√£o e Decis√£o** üìä

**Objetivo**: Apresentar MVP para stakeholders e decidir pr√≥ximos passos

#### Tarefas
- [ ] Criar apresenta√ß√£o em `reports/v3_mvp_presentation.md`:
  - Vis√£o geral v2 ‚Üí v3
  - Demo ao vivo (1-2 protocolos)
  - M√©tricas de sucesso:
    - Tempo de implementa√ß√£o: dias ‚Üí minutos
    - Taxa de sucesso: X%
    - Economia de custo: Y%
    - Qualidade das corre√ß√µes (exemplos)
  - Casos de uso reais
  - Limita√ß√µes e pr√≥ximos passos
  - Proposta de deployment
- [ ] Review com stakeholders
- [ ] Coletar feedback
- [ ] Decidir:
  - [ ] V3 vai para produ√ß√£o? (quando?)
  - [ ] Investir em Fases 8-11 (feedback loop, ROI robusto, API)?
  - [ ] Manter v2 + v3 paralelo? (gradual rollout)

**Entreg√°vel**: Apresenta√ß√£o + decis√£o de deployment

---

## üìä M√©tricas de Sucesso do MVP

### Obrigat√≥rias (deve ter para considerar sucesso)
- ‚úÖ Processa protocolos JSON >3k linhas sem quebrar
- ‚úÖ Taxa de auto-apply bem-sucedida >80%
- ‚úÖ Tempo de implementa√ß√£o: dias ‚Üí <10 minutos
- ‚úÖ Prompt caching >70% (economia brutal de custo)
- ‚úÖ Zero regress√µes da v2 (v2 continua funcionando)
- ‚úÖ Valida√ß√£o estrutural 100% (zero JSON quebrado salvo)

### Desej√°veis (nice-to-have para MVP)
- üéØ Sugest√µes com impact scores (seguran√ßa, economia, esfor√ßo)
- üéØ Diff visual leg√≠vel
- üéØ Logs de auditoria completos
- üéØ CLI amig√°vel para v3

---

## üõ†Ô∏è Setup Inicial (Hoje - Antes do DIA 1)

### 1. Criar Branch V3
```bash
cd "C:\Users\daanm\AgenteV2"
git checkout -b v3-mvp
```

### 2. Estrutura de Pastas V3
```bash
mkdir -p src/agent_v3
mkdir -p src/agent_v3/json_compactor
mkdir -p src/agent_v3/chunking
mkdir -p src/agent_v3/applicator
mkdir -p src/agent_v3/validator
mkdir -p src/agent_v3/scoring
mkdir -p src/agent_v3/diff
mkdir -p src/agent_v3/monitoring
```

### 3. Atualizar requirements.txt (se necess√°rio)
```txt
# V3 Additions (verificar se j√° tem)
jsonschema>=4.0.0  # Para valida√ß√£o estrutural
deepdiff>=6.0.0    # Para diff generator
```

### 4. Criar Script de Valida√ß√£o DIA 1
```bash
touch validate_auto_apply.py
```

---

## ‚ö†Ô∏è Riscos e Mitiga√ß√£o

### Risco 1: Auto-apply n√£o funciona bem (<80% sucesso)
**Mitiga√ß√£o**:
- Valida√ß√£o no DIA 1 antes de implementar
- Se n√£o funcionar ‚Üí refinar prompt ou fazer assistido
- Fallback: modo preview obrigat√≥rio (n√£o auto-apply)

### Risco 2: Protocolos JSON quebram ap√≥s corre√ß√£o
**Mitiga√ß√£o**:
- StructuralValidator obrigat√≥rio antes de salvar
- Testes autom√°ticos de schema
- Rollback autom√°tico se valida√ß√£o falhar

### Risco 3: Custo de tokens explode
**Mitiga√ß√£o**:
- Prompt caching 100% (DIA 8)
- Monitoramento cont√≠nuo via CacheMonitor
- Alertas se custo ultrapassar threshold

### Risco 4: Prazo de 2 semanas n√£o √© suficiente
**Mitiga√ß√£o**:
- Prioriza√ß√£o brutal: CORE MVP vs Nice-to-Have
- Se atrasar ‚Üí cortar Fase 7 (impact scoring) e fazer POST-MVP
- MVP m√≠nimo: JSONCompactor + Auto-Apply + Validation

---

## üéØ Defini√ß√£o de "Done" para MVP

**V3 MVP est√° completo quando:**
1. ‚úÖ 5+ protocolos reais testados com auto-apply >80% sucesso
2. ‚úÖ Suporta protocolos JSON >3k linhas sem quebrar
3. ‚úÖ Pipeline completo funciona end-to-end (v2 an√°lise + v3 corre√ß√£o)
4. ‚úÖ Valida√ß√£o estrutural impede JSON quebrado de ser salvo
5. ‚úÖ Prompt caching reduz custo >50%
6. ‚úÖ Diff generator mostra mudan√ßas de forma leg√≠vel
7. ‚úÖ Documenta√ß√£o b√°sica pronta (README v3, exemplos)
8. ‚úÖ Apresenta√ß√£o para stakeholders realizada
9. ‚úÖ Decis√£o tomada sobre deployment

**Ap√≥s atingir "Done":**
- Merge `v3-mvp` ‚Üí `main` (se aprovado)
- Tag release `v3.0.0-alpha`
- Deploy gradual (v2 + v3 paralelo)
- Coletar feedback de produ√ß√£o
- Planejar Fases 8-11 (POST-MVP)

---

## üìû Contato e Suporte

**Para d√∫vidas durante desenvolvimento:**
- Consultar `roadmap.md` para vis√£o macro
- Consultar `REVIEW_CLAUDE.txt` para princ√≠pios de design v2
- Consultar `dev_history.md` para decis√µes passadas

**Ap√≥s MVP:**
- Atualizar `dev_history.md` com entrada do MVP v3
- Atualizar `roadmap.md` com status das fases
- Criar `CHANGELOG.md` para v3.0.0-alpha

---

**√öltima Atualiza√ß√£o**: 2025-12-01
**Pr√≥xima Revis√£o**: Ap√≥s DIA 14 (apresenta√ß√£o)
