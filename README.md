# üîç Agente Daktus | QA

> Sistema unificado de valida√ß√£o e corre√ß√£o automatizada de protocolos cl√≠nicos usando IA

**Vers√£o Atual**: 3.0-alpha ‚úÖ  
**Status**: Projeto Unificado - Todas as funcionalidades integradas  
**√öltima Atualiza√ß√£o**: 2025-12-01

> **Nota**: Este projeto foi consolidado em um √∫nico reposit√≥rio. O versionamento √© feito via tags/branches Git, n√£o via estrutura de pastas separadas.

---

## üéØ O Que Faz

### Vers√£o 2.x (Atual - Produ√ß√£o)

Valida protocolos cl√≠nicos (JSON) contra playbooks m√©dicos (texto/PDF) para garantir:

- ‚úÖ Consist√™ncia da l√≥gica cl√≠nica
- ‚úÖ Cobertura completa de sintomas
- ‚úÖ Caminhos diagn√≥sticos apropriados
- ‚úÖ Recomenda√ß√µes baseadas em evid√™ncias
- ‚úÖ Identifica√ß√£o de gaps e oportunidades de melhoria

**Entrada**: Protocolo cl√≠nico (JSON) + Playbook m√©dico (Markdown/PDF)  
**Sa√≠da**: Relat√≥rio de valida√ß√£o cl√≠nica (texto + JSON) com an√°lise de gaps e sugest√µes de melhoria priorizadas

### Vers√£o 3.0 (Em Desenvolvimento)

**Evolu√ß√£o transformacional:** De auditoria passiva para corre√ß√£o ativa.

- ‚úÖ Tudo da v2.x
- üî• **Auto-Apply de Melhorias** - Aplica corre√ß√µes automaticamente no JSON
- üî• **Chunking Inteligente** - Processa playbooks gigantes (50-200+ p√°ginas)
- üî• **Prioriza√ß√£o por Impacto** - Sugest√µes ranqueadas por ROI cl√≠nico-financeiro
- üî• **Loop de Feedback** - Aprende com decis√µes cl√≠nicas reais
- üî• **Workflow de Aprova√ß√£o** - Preview, diff visual, rollback autom√°tico

**Resultado:** Redu√ß√£o de 90% no tempo de implementa√ß√£o de melhorias (de dias para minutos).

---

## üöÄ In√≠cio R√°pido

### 1. Instalar Depend√™ncias

```bash
pip install -r requirements.txt
```

### 2. Configurar OpenRouter

Crie um arquivo `.env` na raiz do projeto:

```env
OPENROUTER_API_KEY=sk-or-v1-sua-chave-aqui
```

**Obter chave de API**: https://openrouter.ai/keys

### 3. Executar An√°lise

```bash
python run_qa_cli.py
```

Siga as instru√ß√µes:
1. Selecione o arquivo JSON do protocolo em `models_json/`
2. Selecione o arquivo do playbook (opcional mas recomendado)
3. Escolha o modelo LLM
4. Visualize os resultados em `reports/`

---

## üèóÔ∏è Arquitetura

### Agent V2: Arquitetura Centrada em LLM (Produ√ß√£o)

**Princ√≠pios fundamentais**:
- **Zero l√≥gica cl√≠nica no c√≥digo** - toda intelig√™ncia cl√≠nica vem do LLM
- **Chamada √∫nica ao LLM** - an√°lise abrangente via super prompt
- **Agn√≥stico a especialidades** - funciona identicamente para ORL, AVC, Pediatria, etc.
- **Foco em sugest√µes de melhoria** - recomenda√ß√µes acion√°veis para aprimoramento do protocolo

**Pipeline de Execu√ß√£o**:
```
Playbook + Protocolo ‚Üí protocol_loader (carregamento bruto)
    ‚Üì
prompt_builder (montagem do super prompt com cache)
    ‚Üì
llm_client ‚Üí API OpenRouter (an√°lise abrangente √∫nica)
    ‚Üì
output/validator (valida√ß√£o de schema)
    ‚Üì
pipeline.analyze() ‚Üí Sa√≠da JSON unificada
    ‚Üì
CLI Report Generator ‚Üí reports/*.txt, reports/*.json
```

### üî• Agent V3: Arquitetura Moderna (Em Desenvolvimento)

**Fluxo Unificado**: An√°lise ‚Üí Feedback iterativo ‚Üí Auto-apply assistido ‚Üí Implementa√ß√£o autom√°tica

#### Princ√≠pios Fundamentais

1. **Transpar√™ncia Total**: Usu√°rio v√™ cada etapa do processo (thinking, tasks, progresso)
2. **Controle do Usu√°rio**: Nada acontece sem autoriza√ß√£o expl√≠cita
3. **Aprendizado Cont√≠nuo**: Sistema melhora com feedback de cada an√°lise
4. **Seguran√ßa Primeiro**: Valida√ß√£o rigorosa em cada etapa, zero toler√¢ncia a erros

#### Diferenciais do Modo Enhanced

**1. Relat√≥rios Sofisticados**
- **20-50 sugest√µes** por an√°lise (vs 5-15 da V2)
- Cada sugest√£o com **scores de impacto** (Seguran√ßa 0-10, Economia L/M/A)
- **Rastreabilidade completa**: cada sugest√£o linkada √† evid√™ncia do playbook
- **Estimativa de custo** para aplicar cada sugest√£o

**2. Human-in-the-Loop** (üÜï)
- Usu√°rio revisa cada sugest√£o: Relevante | Irrelevante | Editar
- Sistema **detecta padr√µes** de erro
- **Refinamento autom√°tico** de prompts baseado em feedback
- **Melhoria cont√≠nua**: sistema aprende com cada sess√£o

**3. Controle de Custos Rigoroso** (üÜï)
- **Estimativa pr√©-execu√ß√£o** com 90%+ precis√£o
- **Autoriza√ß√£o obrigat√≥ria** antes de opera√ß√µes custosas
- **Limites configur√°veis** por usu√°rio/sess√£o
- **Rastreamento** real vs estimado

**4. CLI Inspirada no Claude Code** (üÜï)
- **Onboarding interativo** claro e guiado
- **Thinking vis√≠vel**: usu√°rio v√™ o que est√° acontecendo
- **Tasks em tempo real**: progress bars, status updates
- **Formata√ß√£o rica**: tabelas, syntax highlighting, diff colorido

#### Executar V3 (Quando Dispon√≠vel)

```bash
# CLI interativa V3
python run_v3_cli.py

# Ou programaticamente
from agent_v3.pipeline import analyze_and_fix

result = analyze_and_fix(
    protocol_path="models_json/protocolo.json",
    playbook_path="models_json/playbook.md",
    model="anthropic/claude-sonnet-4.5",
    auto_apply=True,
    confidence_threshold=0.90
)
```

#### Documenta√ß√£o V3

- **Plano de Implementa√ß√£o Completo**: `V3_IMPLEMENTATION_PLAN_REFINED.md`
- **Vis√£o Geral e Guia**: `docs/v3_overview.md`
- **README do M√≥dulo**: `src/agent_v3/README.md`

---

### Agent V3: Arquitetura de Corre√ß√£o Automatizada (Roadmap Legacy)

**Evolu√ß√£o transformacional** em 3 etapas:

```
ETAPA 1: PREPROCESSAMENTO INTELIGENTE
Playbook gigante ‚Üí ChunkingEngine ‚Üí Chunks sem√¢nticos
    ‚Üì
SynthesisEngine ‚Üí Playbook-Synth compactado (s√≥ essencial)
    ‚Üì
MemoryManager ‚Üí Contexto mantido entre chunks

ETAPA 2: AN√ÅLISE + CORRE√á√ÉO
Protocolo JSON + Playbook-Synth ‚Üí LLM (an√°lise)
    ‚Üì
Relat√≥rio de melhorias + Scores de impacto
    ‚Üì
ImprovementApplicator ‚Üí Protocolo JSON corrigido (auto-apply)
    ‚Üì
ConfidenceScoring ‚Üí Alta confian√ßa = auto-apply | Baixa = preview

ETAPA 3: APROVA√á√ÉO + APRENDIZADO
Protocolo corrigido ‚Üí ApprovalWorkflow (diff visual)
    ‚Üì
Usu√°rio aprova/rejeita ‚Üí FeedbackCollector
    ‚Üì
LearningEngine ‚Üí Fine-tuning cont√≠nuo baseado em decis√µes reais
```

**Ganhos esperados v3:**
- üî• Tempo de implementa√ß√£o: dias ‚Üí minutos (-90%)
- üî• Custo de tokens: -50-70% (chunking + cache)
- üî• Precis√£o: 80% ‚Üí 95%+ (loop de feedback)
- üî• ROI quantific√°vel: R$ economizados + eventos evitados

---

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente (.env)

```env
# Obrigat√≥rio
OPENROUTER_API_KEY=sk-or-v1-sua-chave-aqui

# Opcional
LLM_MODEL=anthropic/claude-sonnet-4.5  # Modelo padr√£o v3
```

### Modelos Suportados

**Recomendados para v2/v3:**
- `x-ai/grok-4.1-fast:free` ‚≠ê (padr√£o v3 - gratuito, contexto 2M tokens)
- `google/gemini-2.5-flash-preview-09-2025` üîß (v2 padr√£o, baixo custo)
- `anthropic/claude-sonnet-4.5` (alta qualidade, custo m√©dio)

**Outros modelos dispon√≠veis:**
- `x-ai/grok-code-fast-1` (r√°pido, baixo custo)
- `google/gemini-2.5-flash`, `google/gemini-2.5-pro`
- `anthropic/claude-opus-4.5` (m√°xima qualidade)
- `openai/gpt-5-mini`

**Pre√ßos Atualizados (USD por milh√£o de tokens)**:
- Grok 4.1 Fast (Free): $0/$0 (input/output)
- Grok Code Fast 1: $0.20/$1.50
- Gemini 2.5 Flash Preview: $0.30/$2.50
- Gemini 2.5 Flash: $0.30/$2.50
- Gemini 2.5 Pro: $1.25/$10
- Claude Sonnet 4.5: $3/$15
- Claude Opus 4.5: $5/$25

---

## üìä Formato de Sa√≠da

### V2 (Atual)

**Relat√≥rio em Texto** (`reports/*.txt`):
- Resumo da estrutura do protocolo
- Resumo da extra√ß√£o do playbook
- Valida√ß√£o cl√≠nica (cobertura, gaps)
- An√°lise de efici√™ncia
- Sugest√µes de melhoria
- M√©tricas de qualidade

**Relat√≥rio em JSON** (`reports/*.json`):
- Dados estruturados completos
- Todos os resultados da an√°lise
- Metadados (timestamps, modelo usado, tempos de processamento)
- Contagens de entidades (s√≠ndromes, exames, tratamentos)

### V3 (Futuro)

**Adi√ß√µes ao output:**
- ‚úÖ Protocolo JSON corrigido (`reports/*_fixed.json`)
- ‚úÖ Diff visual de mudan√ßas (`reports/*_diff.html`)
- ‚úÖ Scores de impacto por sugest√£o (Seguran√ßa 0-10, Economia R$, Esfor√ßo horas)
- ‚úÖ ROI calculado de cada melhoria
- ‚úÖ Rastreabilidade completa (qual fonte de evid√™ncia justifica cada mudan√ßa)
- ‚úÖ Logs de aprova√ß√£o/rejei√ß√£o (feedback loop)

---

## üîß Solu√ß√£o de Problemas

### "API key n√£o configurada"

**Causa**: `OPENROUTER_API_KEY` n√£o configurado

**Solu√ß√£o**:
```bash
# Verifique se o .env existe
type .env  # Windows
cat .env   # Linux/Mac

# Ou crie manualmente
echo OPENROUTER_API_KEY=sk-or-v1-sua-chave > .env
```

### "Nenhum arquivo de protocolo encontrado"

**Causa**: Nenhum arquivo JSON em `models_json/`

**Solu√ß√£o**: Adicione arquivos JSON de protocolos no diret√≥rio `models_json/`

### "Playbook muito grande - context overflow"

**Causa (v2)**: Playbook >50 p√°ginas excede janela de contexto

**Solu√ß√£o tempor√°ria**: Reduza playbook manualmente ou divida em se√ß√µes

**Solu√ß√£o definitiva (v3)**: ChunkingEngine processar√° playbooks gigantes automaticamente

---

## üìö Documenta√ß√£o

**Documenta√ß√£o Oficial** (consolidada em 3 arquivos principais):

- **Este arquivo** (`README.md`) - Vis√£o geral e uso
- **`roadmap.md`** - Roadmap completo v2 ‚Üí v3
- **`dev_history.md`** - Hist√≥rico de desenvolvimento (log append-only)

**Recursos Adicionais**:

- `REVIEW_CLAUDE.txt` - Especifica√ß√£o completa do Agent V2
- `src/agent_v2/` - C√≥digo-fonte do Agent V2

---

## üéØ Princ√≠pios-Chave

### Princ√≠pios de Design do Agent V2/V3

1. **Zero L√≥gica Cl√≠nica no C√≥digo**
   - Todas as decis√µes cl√≠nicas v√™m do LLM
   - Sem regras hardcoded, regex ou heur√≠sticas
   - C√≥digo √© pura orquestra√ß√£o

2. **Chamada √önica ao LLM** (v2) ‚Üí **Chunking Inteligente** (v3)
   - v2: Um super prompt abrangente
   - v3: Processamento incremental com s√≠ntese

3. **Agn√≥stico a Especialidades**
   - Mesmo caminho de c√≥digo para todas as especialidades m√©dicas
   - Sem l√≥gica `if especialidade == "ORL"`
   - Conhecimento espec√≠fico de especialidade nos playbooks, n√£o no c√≥digo

4. **De Passivo para Ativo** (v3)
   - v2: Identifica problemas
   - v3: Identifica + Corrige automaticamente

5. **Fail-Fast com Seguran√ßa**
   - Erros s√£o registrados e propagados imediatamente
   - Auto-apply somente com alta confian√ßa (>90%)
   - Aprova√ß√£o humana obrigat√≥ria para mudan√ßas cr√≠ticas

6. **Aprendizado Cont√≠nuo** (v3)
   - Sistema aprende com decis√µes cl√≠nicas reais
   - Fine-tuning baseado em feedback
   - Precis√£o melhora ao longo do tempo

---

## üìà Performance

### Agent V2 (Atual)
- **Lat√™ncia p95**: ‚â§ 60 segundos
- **Custo por an√°lise**: ~R$ 0,25-0,50 (depende do modelo)
- **Taxa de sucesso**: ‚â• 95%
- **Cache de prompts**: Reduz at√© 90% do custo em an√°lises repetidas

### Agent V3 (Expectativa)
- **Lat√™ncia p95**: ‚â§ 90 segundos (chunking + auto-apply)
- **Custo por an√°lise**: ~R$ 0,15-0,30 (-50% via chunking otimizado)
- **Taxa de sucesso**: ‚â• 98%
- **Tempo de implementa√ß√£o de melhorias**: Dias ‚Üí Minutos (-90%)
- **Precis√£o de sugest√µes**: 80% ‚Üí 95%+ (ap√≥s 3-6 meses de feedback)

---

## üîó Links √öteis

- **OpenRouter**: https://openrouter.ai
- **Chaves de API**: https://openrouter.ai/keys
- **Cat√°logo de Modelos**: https://openrouter.ai/models
- **Anthropic Claude**: https://www.anthropic.com/claude

---

## üìù Uso Program√°tico

### V2 (Atual)

```python
from agent_v2.pipeline import analyze

# An√°lise completa
resultado = analyze(
    protocol_path="models_json/protocolo.json",
    playbook_path="models_json/playbook.md",
    model="anthropic/claude-sonnet-4.5"
)

# Resultado cont√©m:
# - protocol_analysis: an√°lise estrutural e extra√ß√£o cl√≠nica
# - improvement_suggestions: sugest√µes de melhoria priorizadas
# - metadata: informa√ß√µes sobre processamento, modelo, qualidade
```

### V3 (Futuro)

```python
from agent_v3.pipeline import analyze_and_fix

# An√°lise + Corre√ß√£o automatizada
resultado = analyze_and_fix(
    protocol_path="models_json/protocolo.json",
    playbook_path="models_json/playbook_gigante.pdf",  # Suporta playbooks massivos
    model="anthropic/claude-sonnet-4.5",
    auto_apply=True,  # Aplica corre√ß√µes automaticamente
    confidence_threshold=0.90  # S√≥ auto-apply se confian√ßa >90%
)

# Resultado cont√©m:
# - protocol_analysis: an√°lise estrutural
# - improvement_suggestions: sugest√µes ranqueadas por impacto
# - fixed_protocol: protocolo JSON corrigido
# - changes_diff: diff visual de mudan√ßas
# - impact_scores: scores de seguran√ßa, economia, esfor√ßo
# - metadata: custo, tempo, confian√ßa de cada mudan√ßa
```

---

## üéØ Pr√≥ximos Passos

### Para Usu√°rios
1. ‚úÖ Use o modo Standard para valida√ß√£o b√°sica de protocolos
2. ‚úÖ Use o modo Enhanced para an√°lise expandida e reconstru√ß√£o autom√°tica
3. ‚úÖ Forne√ßa feedback para melhorar continuamente o sistema

### Para Desenvolvedores
1. ‚è≥ Ver roadmap completo em `docs/roadmap.md`
2. ‚è≥ Ver plano de implementa√ß√£o em `docs/V3_IMPLEMENTATION_PLAN_REFINED.md`
3. ‚è≥ Contribuir com melhorias e novas funcionalidades

---

**Para o roadmap detalhado, veja [`docs/roadmap.md`](docs/roadmap.md)**  
**Para o hist√≥rico de desenvolvimento, veja [`docs/dev_history.md`](docs/dev_history.md)**